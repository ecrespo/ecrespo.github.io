<!doctype html>
<html lang="es" itemscope itemtype="http://schema.org/Person">
<head>
            <meta charset="utf-8">
        <!-- Site Meta Data -->
        <title>Funciones de activación para un perceptron</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="">
        <meta name="author" content="Ernesto Crespo">

        <link rel="shortcut icon" href="">

        <!-- schema.org -->
        <meta itemprop="name" content="Página de Seraph">
        <meta itemprop="image" content="">
        <meta itemprop="description" content="">

        <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,600,700' rel='stylesheet' type='text/css'>
        <!-- Style Meta Data -->
        <link rel="stylesheet" href="https://ecrespo.github.io/theme/css/style.css" type="text/css"/>
        <link rel="stylesheet" href="https://ecrespo.github.io/theme/css/pygments.css" type="text/css"/>

        <!-- Feed Meta Data -->
            <link href="https://ecrespo.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
                  title="Página de Seraph ATOM Feed"/>

        <!-- Twitter Feed -->
        <meta name="twitter:card" content="summary">
        <meta name="twitter:site" content="">
        <meta name="twitter:image" content="">

    <meta name="twitter:creator" content="">
    <meta name="twitter:url" content="https://ecrespo.github.io/funciones-de-activacion-para-un-perceptron.html">
    <meta name="twitter:title" content="Página de Seraph ~ Funciones de activación para un perceptron">
    <meta name="twitter:description" content="En el artículo (introducción al perceptron), se muestra el perceptron con la función de activación que en la figura es una onda cuadrada, pero puede ser también otro tipo de función. En el artículo (construir una red neuronal en pocos minutos), se muestra la función de activación llamada sigmoide. Y …">

    <!-- Facebook Meta Data -->
    <meta property="og:title" content="Página de Seraph ~ Funciones de activación para un perceptron"/>
    <meta property="og:description" content="En el artículo (introducción al perceptron), se muestra el perceptron con la función de activación que en la figura es una onda cuadrada, pero puede ser también otro tipo de función. En el artículo (construir una red neuronal en pocos minutos), se muestra la función de activación llamada sigmoide. Y …"/>
    <meta property="og:image" content=""/>
</head>

<body>
<!-- Sidebar -->
<aside>
    <!--<center><a href="https://ecrespo.github.io"><img id="avatar" src=""></a></center>-->
    <h1>Página de Seraph</h1>
    <br>


    <nav class="nav">
        <ul class="list-bare">

                <li><a class="nav__link" href="/archives.html">Archives</a></li>
                <li><a class="nav__link" href="/categories.html">Categories</a></li>
                <li><a class="nav__link" href="/tags.html">Tags</a></li>

                <li><a class="nav__link" href="https://ecrespo.github.io/pages/About.html">Acerca</a></li>
                <li><a class="nav__link" href="https://ecrespo.github.io/pages/Contacto.html">Contacto</a></li>

        </ul>
    </nav>

    <p class="social">
                <a href="https://medium.com/@_seraph1" target="_blank"><img
                        src="https://ecrespo.github.io/theme/images/icons/medium.png"></a>
                <a href="http://ve.linkedin.com/in/ernestocrespo" target="_blank"><img
                        src="https://ecrespo.github.io/theme/images/icons/linkedin.png"></a>
                <a href="https://github.com/ecrespo" target="_blank"><img
                        src="https://ecrespo.github.io/theme/images/icons/github.png"></a>
                <a href="https://google.com/+ErnestoCrespo" target="_blank"><img
                        src="https://ecrespo.github.io/theme/images/icons/google.png"></a>
                <a href="https://twitter.com/_seraph1" target="_blank"><img
                        src="https://ecrespo.github.io/theme/images/icons/twitter.png"></a>
                <a href="https://www.facebook.com/ernesto.crespo" target="_blank"><img
                        src="https://ecrespo.github.io/theme/images/icons/facebook.png"></a>
                <a href="https://gitlab.com/ecrespo" target="_blank"><img
                        src="https://ecrespo.github.io/theme/images/icons/gitlab.png"></a>
                <a href="https://soundcloud.com/ernesto-crespo" target="_blank"><img
                        src="https://ecrespo.github.io/theme/images/icons/soundcloud.png"></a>
                <a href="//www.seraph.to/feeds/all.atom.xml" target="_blank"><img
                        src="https://ecrespo.github.io/theme/images/icons/rss.png"></a>
            <a href="https://ecrespo.github.io/feeds/all.atom.xml" rel="alternate">
                <img src="https://ecrespo.github.io/theme/images/icons/rss.png"></a>
    </p>

        <h2>Categories</h2>
        <ul class="navbar">
                <li><a
                        href="https://ecrespo.github.io/category/accesibilidad.html">Accesibilidad</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/anuncio.html">Anuncio</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/anuncios.html">Anuncios</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/aplicacion-android.html">Aplicación Android</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/asterisk-debian-linux.html">Asterisk, Debian, Linux</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/charla.html">Charla</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/charla-python.html">Charla Python</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/debian-linux-mac-book.html">Debian, Linux, Mac Book</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/debian-maemo-nokia-n810-python.html">Debian, maemo, Nokia N810, Python</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/demostracion-aplicacion-para-android.html">Demostración Aplicación para Android</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/desarrollomovil.html">Desarrollo,Movil</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/evento.html">Evento</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/general.html">General</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/linux.html">Linux</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/linuxdebian.html">Linux,Debian</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/linuxdesarrollo.html">Linux,Desarrollo</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/linuxempaquetado.html">Linux,Empaquetado</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/linuxofimaticadesarrollo.html">Linux,Ofimatica,Desarrollo</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/movil-nokia.html">Movil, Nokia</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/nokia-n810.html">Nokia N810</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/nokia-n810-debian-maemo.html">Nokia N810 Debian Maemo</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/posts.html">posts</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/resumen-2010.html">Resumen 2010</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/sistemas-operativos.html">Sistemas Operativos</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial.html">Tutorial</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-android.html">Tutorial Android</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-de-arduino.html">Tutorial de Arduino</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-de-data-science.html">Tutorial de Data Science</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-de-docker.html">Tutorial de Docker</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-de-integracion-continua.html">Tutorial de integración continua</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-de-linux.html">Tutorial de Linux</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-de-python.html">Tutorial de Python</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-de-python-en-android.html">Tutorial de Python en Android</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-de-python-y-linux.html">Tutorial de Python y Linux</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-de-python-y-pyqt.html">Tutorial de Python y PyQt</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-debian-bsd-y-python.html">Tutorial Debian BSD y Python</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-linux.html">Tutorial Linux</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-linux-y-python.html">Tutorial Linux y Python</a></li>
                <li class="active"><a
                        href="https://ecrespo.github.io/category/tutorial-python.html">Tutorial Python</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-python-en-android.html">Tutorial Python en Android</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorial-python-y-linux.html">Tutorial Python y Linux</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/tutorialdesarrollo.html">Tutorial,Desarrollo</a></li>
                <li><a
                        href="https://ecrespo.github.io/category/xml-rpcpython.html">XML-RPC,Python</a></li>
        </ul>


</aside>

<!-- Content -->
<article>
    <section id="content">
        <article>
            <h2 class="post_title post_detail"><a href="https://ecrespo.github.io/funciones-de-activacion-para-un-perceptron.html" rel="bookmark"
                                                  title="Permalink to Funciones de activación para un perceptron">Funciones de activación para un perceptron</a></h2>
            <div class="entry-content blog-post">
                <p>En el artículo (<a href="https://www.seraph.to/introduccion-al-perceptron-con-python.html">introducción al perceptron</a>), se muestra el perceptron con la función de activación que en la figura es una onda cuadrada, pero puede ser también otro tipo de función.</p>
<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-1.png"> </p>
<p>En el artículo  (<a href="https://www.seraph.to/construir-una-red-neuronal-en-pocos-minutos.html">construir una red neuronal en pocos minutos</a>), se muestra la función de activación llamada sigmoide.</p>
<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-2.png"> </p>
<p>Y en el artículo (<a href="https://www.seraph.to/una-red-neuronal-para-aprendizaje-supervisado-usando-scikit-learn.html">Una red Neuronal para aprendizaje supervisado usando Scikit-learn</a>) se usa la función tanh.</p>
<p>Scikit-learn para  multi-layer perceptron maneja varios tipos de funciones de activación (<a href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">documentación</a>) como lo son:</p>
<ul>
<li>identity: La función de activación es <code>f(x)=x</code>.</li>
<li>logistic: La función de activación es la función sigmoide <code>f(x)=1/(1+exp(-x))</code>.</li>
<li>tanh: La función de activación es la función tangente hiperbolico <code>f(x)=tanh(x)</code>.</li>
<li>relu: La función de activación es función rectificada de recta unitaria <code>f(x)=max(0,x)</code>.</li>
</ul>
<p>El código mostrará las distintas funciones y sus gráficas, luego se toma la red neuronal del artículo <a href="https://www.seraph.to/una-red-neuronal-para-aprendizaje-supervisado-usando-scikit-learn.html">Una red Neuronal para aprendizaje supervisado usando Scikit-learn</a>, usando distintas funciones de activación, se entrena a la neurona con cada función de activación y se busca predecir el resultado.</p>
<p>A continuación el código:</p>
<p>In [1]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se importa numpy y matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div>

<p>In [2]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se define el rango de valores</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div>

<p>In [3]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Onda cuadrada</span>
<span class="k">def</span> <span class="nf">cuadrada</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">z</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>

<p>In [4]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se calcula la onda cuadrada a partir del rango de valores</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">cuadrada</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div>

<p>In [5]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se gráfica la onda cuadrada</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">a</span><span class="p">)</span>
</code></pre></div>

<p>Out[5]:</p>
<div class="highlight"><pre><span></span><code><span class="p">[</span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span> <span class="n">at</span> <span class="mh">0x7f90ba52c278</span><span class="o">&gt;</span><span class="p">]</span>
</code></pre></div>

<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-3.png"> </p>
<p>In [6]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se define la función Identidad</span>
<span class="k">def</span> <span class="nf">identidad</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div>

<p>In [7]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se calcula la función identidad a partir del rango de valores</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">identidad</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div>

<p>In [8]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se gráfica.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
</code></pre></div>

<p>Out[8]:</p>
<div class="highlight"><pre><span></span><code><span class="p">[</span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span> <span class="n">at</span> <span class="mh">0x7f90ba49e7f0</span><span class="o">&gt;</span><span class="p">]</span>
</code></pre></div>

<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-4.png"> </p>
<p>In [9]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Función ReLU</span>
<span class="k">def</span> <span class="nf">ReLU</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">z</span> <span class="o">*</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div>

<p>In [10]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se calcula la función ReLU a partir del rango de valores</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div>

<p>In [11]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se gráfica la función</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
</code></pre></div>

<p>Out[11]:</p>
<div class="highlight"><pre><span></span><code><span class="p">[</span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span> <span class="n">at</span> <span class="mh">0x7f90ba46c6d8</span><span class="o">&gt;</span><span class="p">]</span>
</code></pre></div>

<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-5.png"> </p>
<p>In [12]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Función tangente hiperbolico</span>
<span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</code></pre></div>

<p>In [13]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se calcula la tangente hiperbolica a partir del rango de valores</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">tanh</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div>

<p>In [14]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se gráfica</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">d</span><span class="p">)</span>
</code></pre></div>

<p>Out[14]:</p>
<div class="highlight"><pre><span></span><code><span class="err">[&lt;matplotlib.lines.Line2D at 0x7f90ba42e550&gt;]</span>
</code></pre></div>

<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-6.png"> </p>
<p>In [15]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Función sigmoide</span>
<span class="k">def</span> <span class="nf">sigmoide</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</code></pre></div>

<p>In [16]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se calcula la sigmoide a partir del rango de valores</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">sigmoide</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div>

<p>In [17]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se gráfica la función</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">e</span><span class="p">)</span>
</code></pre></div>

<p>Out[17]:</p>
<div class="highlight"><pre><span></span><code><span class="p">[</span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span> <span class="n">at</span> <span class="mh">0x7f90ba3f0be0</span><span class="o">&gt;</span><span class="p">]</span>
</code></pre></div>

<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-7.png"> </p>
<p>La diferencia entre las funciones de activación es lo suavizada o no de cada curva. Osea, que tan abrupta es su pendiente, o la derivada de la función.</p>
<p>A continuación se crea una red neuronal usando scikit-learn  </p>
<p>In [18]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se importa de la red neuronal MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
</code></pre></div>

<p>In [19]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se definen los datos de entrada</span>
<span class="n">datos_entrada</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
    <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
<span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<p>In [20]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se definen los datos de salida</span>
<span class="n">datos_salida</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,)</span>
</code></pre></div>

<p>In [21]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se crea la red neuronal con función de activación relu y 100 mil iteraciones</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div>

<p>In [22]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se entrena a la red neuronal</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">,</span><span class="n">datos_salida</span><span class="p">)</span>
</code></pre></div>

<p>Out[22]:</p>
<div class="highlight"><pre><span></span><code><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
       <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span>
       <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span>
       <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
       <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">power_t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
       <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
       <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<p>In [23]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se hace la predicción</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;prediccion:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">))</span>

<span class="n">prediccion</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span><span class="p">]</span>
</code></pre></div>

<p>El resultado que devuelve la red neuronal debería ser [0,1,1,0] y devuelve [0,1,0,1] el cual es errado.
Se repite la construcción de la red neuronal, pero ahora usando la función de activación identity.</p>
<p>In [24]:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;identity&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div>

<p>In [25]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se entrena a la red neuronal</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">,</span><span class="n">datos_salida</span><span class="p">)</span>
</code></pre></div>

<p>Out[25]:</p>
<div class="highlight"><pre><span></span><code><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;identity&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
       <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span>
       <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span>
       <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
       <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">power_t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
       <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
       <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<p>In [26]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se hace la predicción</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;prediccion:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">))</span>

<span class="n">prediccion</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
</code></pre></div>

<p>El resultado que devuelve la red neuronal debería ser [0,1,1,0] y devuelve [0,0,0,0] el cual es errado.
Se repite la construcción de la red neuronal, pero ahora usando la función de activación sigmoide (logistic).  </p>
<p>In [27]:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;logistic&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div>

<p>In [28]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se entrena a la red neuronal</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">,</span><span class="n">datos_salida</span><span class="p">)</span>
</code></pre></div>

<p>Out[28]:</p>
<div class="highlight"><pre><span></span><code><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;logistic&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
       <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span>
       <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span>
       <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
       <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">power_t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
       <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
       <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<p>In [29]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se hace la predicción</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;prediccion:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">))</span>

<span class="n">prediccion</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span><span class="p">]</span>
</code></pre></div>

<p>El resultado que devuelve la red neuronal debería ser [0,1,1,0] y devuelve [1,1,1,1] el cual es errado.
Se repite la construcción de la red neuronal, pero ahora usando la función de activación tanh.  </p>
<p>In [33]:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div>

<p>In [34]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se entrena a la red neuronal</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">,</span><span class="n">datos_salida</span><span class="p">)</span>
</code></pre></div>

<p>Out[34]:</p>
<div class="highlight"><pre><span></span><code><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
       <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span>
       <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span>
       <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
       <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">power_t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
       <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
       <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<p>In [35]:</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Se hace la predicción</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;prediccion:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">))</span>

<span class="n">prediccion</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span><span class="p">]</span>
</code></pre></div>

<p>El resultado que devuelve la red neuronal debería ser [0,1,1,0] y devuelve [0,1,1,0] el cual es el resultado esperado. Esto demuestra que es muy importante seleccionar la función de activación correcta a la hora de definir una red neuronal y entrenarla.</p>
<h2></h2>
<p>¡Haz tu donativo!
Si te gustó el artículo puedes realizar un donativo con Bitcoin (BTC)
usando la billetera digital de tu preferencia a la siguiente
dirección: 17MtNybhdkA9GV3UNS6BTwPcuhjXoPrSzV</p>
<p>O Escaneando el código QR desde la billetera:</p>
<p><img alt="17MtNybhdkA9GV3UNS6BTwPcuhjXoPrSzV" src="./images/17MtNybhdkA9GV3UNS6BTwPcuhjXoPrSzV.png"></p>
            </div>
            <div class="post_list">
                <span>By </span>
                <a href="https://ecrespo.github.io/author/ernesto-crespo.html">@Ernesto Crespo</a>
                <span> in </span>
                <span class="post_category"><a href="https://ecrespo.github.io/category/tutorial-python.html" rel="bookmark"
                                               title="Permalink to Tutorial Python">[ Tutorial Python ]</a></span>
                <span class="post_date">mar 13 febrero 2018</span>
                <div><span>Tags : </span>
                            <span><a href="https://ecrespo.github.io/tag/scikit-learn.html">#Scikit-learn, </a></span>
                            <span><a href="https://ecrespo.github.io/tag/python.html">#Python, </a></span>
                            <span><a href="https://ecrespo.github.io/tag/inteligencia-artificial.html">#Inteligencia Artificial, </a></span>
                </div>

                <div class="entry-social">
                    <span class="twitter"><a target="_blank" rel="nofollow"
                                             onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=400,width=700');return false;"
                                             title="Twitter"
                                             href="https://twitter.com/share?url=https://ecrespo.github.io/funciones-de-activacion-para-un-perceptron.html&text=Funciones de activación para un perceptron&via="><img
                            src="https://ecrespo.github.io/theme/images/icons/twitter-s.png"></a></span>

                    <span class="gplus"><a target="_blank" title="Google +"
                                           href="https://plus.google.com/share?url=https://ecrespo.github.io/funciones-de-activacion-para-un-perceptron.html&hl=fr"
                                           rel="nofollow"
                                           onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=450,width=650');return false;"><img
                            src="https://ecrespo.github.io/theme/images/icons/google-s.png"></a></span>

                    <span class="facebook"><a target="_blank" title="Facebook" rel="nofollow"
                                              onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=500,width=700');return false;"
                                              href="https://www.facebook.com/sharer.php?u=https://ecrespo.github.io/funciones-de-activacion-para-un-perceptron.html&t=Funciones de activación para un perceptron"><img
                            src="https://ecrespo.github.io/theme/images/icons/facebook-s.png"></a></span>

                    <a target="_blank" title="Linkedin"
                       href="https://www.linkedin.com/shareArticle?mini=true&url=https://ecrespo.github.io/funciones-de-activacion-para-un-perceptron.html&title=Funciones de activación para un perceptron"
                       rel="nofollow"
                       onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=450,width=650');return false;"><img
                            src="https://ecrespo.github.io/theme/images/icons/linkedin-s.png"></a>

                    <span class="mail"><a
                            href="mailto:?subject=Funciones de activación para un perceptron&amp;body=Viens découvrir un article à propos de [Funciones de activación para un perceptron] sur le site de Ernesto Crespo. https://ecrespo.github.io/funciones-de-activacion-para-un-perceptron.html"
                            title="Share by Email" target="_blank"><img
                            src="https://ecrespo.github.io/theme/images/icons/mail-s.png"></a></span>
                </div>
            </div>
                <div class="comments">
                    <h2>Comments !</h2>
                    <div id="disqus_thread"></div>
                    <script type="text/javascript">
                        var disqus_identifier = "funciones-de-activacion-para-un-perceptron.html";
                        (function () {
                            var dsq = document.createElement('script');
                            dsq.type = 'text/javascript';
                            dsq.async = true;
                            dsq.src = 'https://https://seraphto.disqus.com.disqus.com/embed.js';
                            (document.getElementsByTagName('head')[0] ||
                            document.getElementsByTagName('body')[0]).appendChild(dsq);
                        })();
                    </script>
                </div>
        </article>
    </section>
</article>

<!-- Footer -->
    <footer>
        <p>
            Blog powered by <a href="http://getpelican.com/">Pelican</a>,
            which takes great advantage of <a href="http://python.org">Python</a>.
            Theme <a href="https://github.com/parbhat/pelican-blue">Pelican-Blue</a> by <a
                href="https://parbhatpuri.com/">@parbhat</a>.
        </p>
    </footer>

    <!-- Analytics -->
    <script type="text/javascript">
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-131517246-1']);
        _gaq.push(['_trackPageview']);
        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>

</body>
</html>