
<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="https://blog.seraph.to/theme/stylesheet/style.min.css">


    <link id="pygments-light-theme" rel="stylesheet" type="text/css"
          href="https://blog.seraph.to/theme/pygments/monokai.min.css">



  <link rel="stylesheet" type="text/css" href="https://blog.seraph.to/theme/font-awesome/css/fontawesome.css">
  <link rel="stylesheet" type="text/css" href="https://blog.seraph.to/theme/font-awesome/css/brands.css">
  <link rel="stylesheet" type="text/css" href="https://blog.seraph.to/theme/font-awesome/css/solid.css">



  <!-- Chrome, Firefox OS and Opera -->
  <meta name="theme-color" content="#e5e5ff">
  <!-- Windows Phone -->
  <meta name="msapplication-navbutton-color" content="#e5e5ff">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Microsoft EDGE -->
  <meta name="msapplication-TileColor" content="#e5e5ff">

  <link href="https://blog.seraph.to/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Página de Seraph Atom">


<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-131517246-1', 'auto');
  ga('send', 'pageview');
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-300366206"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-300366206');
</script>






 

<meta name="author" content="Ernesto Crespo" />
<meta name="description" content="En el artículo (introducción al perceptron), se muestra el perceptron con la función de activación que en la figura es una onda cuadrada, pero puede ser también otro tipo de función. En el artículo (construir una red neuronal en pocos minutos), se muestra la función de activación llamada sigmoide. Y …" />
<meta name="keywords" content="Scikit-learn, Python, Inteligencia Artificial">


  <meta property="og:site_name" content="Página de Seraph"/>
  <meta property="og:title" content="Funciones de activación para un perceptron"/>
  <meta property="og:description" content="En el artículo (introducción al perceptron), se muestra el perceptron con la función de activación que en la figura es una onda cuadrada, pero puede ser también otro tipo de función. En el artículo (construir una red neuronal en pocos minutos), se muestra la función de activación llamada sigmoide. Y …"/>
  <meta property="og:locale" content="es_VE"/>
  <meta property="og:url" content="https://blog.seraph.to/funciones-de-activacion-para-un-perceptron.html"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2018-02-13 09:00:00-04:00"/>
  <meta property="article:modified_time" content=""/>
  <meta property="article:author" content="https://blog.seraph.to/author/ernesto-crespo.html">
  <meta property="article:section" content="Tutorial Python"/>
  <meta property="article:tag" content="Scikit-learn"/>
  <meta property="article:tag" content="Python"/>
  <meta property="article:tag" content="Inteligencia Artificial"/>
  <meta property="og:image" content="//s.gravatar.com/avatar/7fab2070e149e57fe99da94d7ccbad6b?s=120">

  <title>Página de Seraph &ndash; Funciones de activación para un perceptron</title>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "pub-0261001661746989",
      enable_page_level_ads: true
    });
  </script>

</head>
<body class="light-theme">

<aside>
  <div>
    <a href="https://blog.seraph.to/">
      <img src="//s.gravatar.com/avatar/7fab2070e149e57fe99da94d7ccbad6b?s=120" alt="Ernesto Crespo" title="Ernesto Crespo">
    </a>

    <h1>
      <a href="https://blog.seraph.to/">Ernesto Crespo</a>
    </h1>

    <p>Data Scientist </p>


    <nav>
      <ul class="list">


            <li>
              <a target="_self"
                 href="https://blog.seraph.to/pages/About.html#About">
                Acerca
              </a>
            </li>
            <li>
              <a target="_self"
                 href="https://blog.seraph.to/pages/Contacto.html#Contacto">
                Contacto
              </a>
            </li>

      </ul>
    </nav>

    <ul class="social">
      <li>
        <a class="sc-medium"
           href="https://medium.com/@_seraph1"
           target="_blank">
          <i class="fa-brands fa-medium"></i>
        </a>
      </li>
      <li>
        <a class="sc-linkedin"
           href="http://ve.linkedin.com/in/ernestocrespo"
           target="_blank">
          <i class="fa-brands fa-linkedin"></i>
        </a>
      </li>
      <li>
        <a class="sc-github"
           href="https://github.com/ecrespo"
           target="_blank">
          <i class="fa-brands fa-github"></i>
        </a>
      </li>
      <li>
        <a class="sc-google"
           href="https://google.com/+ErnestoCrespo"
           target="_blank">
          <i class="fa-brands fa-google"></i>
        </a>
      </li>
      <li>
        <a class="sc-twitter"
           href="https://twitter.com/_seraph1"
           target="_blank">
          <i class="fa-brands fa-twitter"></i>
        </a>
      </li>
      <li>
        <a class="sc-facebook"
           href="https://www.facebook.com/ernesto.crespo"
           target="_blank">
          <i class="fa-brands fa-facebook"></i>
        </a>
      </li>
      <li>
        <a class="sc-gitlab"
           href="https://gitlab.com/ecrespo"
           target="_blank">
          <i class="fa-brands fa-gitlab"></i>
        </a>
      </li>
      <li>
        <a class="sc-soundcloud"
           href="https://soundcloud.com/ernesto-crespo"
           target="_blank">
          <i class="fa-brands fa-soundcloud"></i>
        </a>
      </li>
      <li>
        <a class="sc-deepnote"
           href="https://deepnote.com/@ernesto-crespo"
           target="_blank">
          <i class="fa-brands fa-deepnote"></i>
        </a>
      </li>
      <li>
        <a class="sc-kaggle"
           href="https://www.kaggle.com/ecrespoa"
           target="_blank">
          <i class="fa-brands fa-kaggle"></i>
        </a>
      </li>
      <li>
        <a class="sc-rss"
           href="//blog.seraph.to/feeds/all.atom.xml"
           target="_blank">
          <i class="fa-solid fa-rss"></i>
        </a>
      </li>
    </ul>
  </div>

    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <ins class="adsbygoogle ads-aside"
         data-ad-client="pub-0261001661746989"
         data-ad-slot="1234561"></ins>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
</aside>
  <main>
      <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      <ins class="adsbygoogle ads-responsive"
           data-ad-client="pub-0261001661746989"
           data-ad-slot="1234562"></ins>
      <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

<nav>
  <a href="https://blog.seraph.to/">Home</a>

  <a href="/archives.html">Archives</a>
  <a href="/categories.html">Categories</a>
  <a href="/tags.html">Tags</a>

  <a href="https://blog.seraph.to/feeds/all.atom.xml">Atom</a>

</nav>

<article class="single">
  <header>
      
    <h1 id="funciones-de-activacion-para-un-perceptron">Funciones de activación para un perceptron</h1>
    <p>
      Posted on Tue 13 February 2018 in <a href="https://blog.seraph.to/category/tutorial-python.html">Tutorial Python</a>

        &#8226; 4 min read
    </p>
  </header>

    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <ins class="adsbygoogle ads-responsive"
         data-ad-client="pub-0261001661746989"
         data-ad-slot="1234565"></ins>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
    </script>

  <div>
    <p>En el artículo (<a href="https://www.seraph.to/introduccion-al-perceptron-con-python.html">introducción al perceptron</a>), se muestra el perceptron con la función de activación que en la figura es una onda cuadrada, pero puede ser también otro tipo de función.</p>
<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-1.png"> </p>
<p>En el artículo  (<a href="https://www.seraph.to/construir-una-red-neuronal-en-pocos-minutos.html">construir una red neuronal en pocos minutos</a>), se muestra la función de activación llamada sigmoide.</p>
<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-2.png"> </p>
<p>Y en el artículo (<a href="https://www.seraph.to/una-red-neuronal-para-aprendizaje-supervisado-usando-scikit-learn.html">Una red Neuronal para aprendizaje supervisado usando Scikit-learn</a>) se usa la función tanh.</p>
<p>Scikit-learn para  multi-layer perceptron maneja varios tipos de funciones de activación (<a href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">documentación</a>) como lo son:</p>
<ul>
<li>identity: La función de activación es <code>f(x)=x</code>.</li>
<li>logistic: La función de activación es la función sigmoide <code>f(x)=1/(1+exp(-x))</code>.</li>
<li>tanh: La función de activación es la función tangente hiperbolico <code>f(x)=tanh(x)</code>.</li>
<li>relu: La función de activación es función rectificada de recta unitaria <code>f(x)=max(0,x)</code>.</li>
</ul>
<p>El código mostrará las distintas funciones y sus gráficas, luego se toma la red neuronal del artículo <a href="https://www.seraph.to/una-red-neuronal-para-aprendizaje-supervisado-usando-scikit-learn.html">Una red Neuronal para aprendizaje supervisado usando Scikit-learn</a>, usando distintas funciones de activación, se entrena a la neurona con cada función de activación y se busca predecir el resultado.</p>
<p>A continuación el código:</p>
<p>In [1]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se importa numpy y matplotlib</span></span>
<span class="code-line"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span></span>
<span class="code-line"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span></span>
<span class="code-line"><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span></span>
<span class="code-line"></code></pre></div>

<p>In [2]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se define el rango de valores</span></span>
<span class="code-line"><span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [3]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Onda cuadrada</span></span>
<span class="code-line"><span class="k">def</span> <span class="nf">cuadrada</span><span class="p">(</span><span class="n">z</span><span class="p">):</span></span>
<span class="code-line">    <span class="k">return</span> <span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">z</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [4]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se calcula la onda cuadrada a partir del rango de valores</span></span>
<span class="code-line"><span class="n">a</span> <span class="o">=</span> <span class="n">cuadrada</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [5]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se gráfica la onda cuadrada</span></span>
<span class="code-line"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">a</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>Out[5]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="p">[</span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span> <span class="n">at</span> <span class="mh">0x7f90ba52c278</span><span class="o">&gt;</span><span class="p">]</span></span>
<span class="code-line"></code></pre></div>

<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-3.png"> </p>
<p>In [6]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se define la función Identidad</span></span>
<span class="code-line"><span class="k">def</span> <span class="nf">identidad</span><span class="p">(</span><span class="n">z</span><span class="p">):</span></span>
<span class="code-line">    <span class="k">return</span> <span class="n">z</span></span>
<span class="code-line"></code></pre></div>

<p>In [7]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se calcula la función identidad a partir del rango de valores</span></span>
<span class="code-line"><span class="n">b</span> <span class="o">=</span> <span class="n">identidad</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [8]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se gráfica.</span></span>
<span class="code-line"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">b</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>Out[8]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="p">[</span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span> <span class="n">at</span> <span class="mh">0x7f90ba49e7f0</span><span class="o">&gt;</span><span class="p">]</span></span>
<span class="code-line"></code></pre></div>

<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-4.png"> </p>
<p>In [9]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Función ReLU</span></span>
<span class="code-line"><span class="k">def</span> <span class="nf">ReLU</span><span class="p">(</span><span class="n">z</span><span class="p">):</span></span>
<span class="code-line">    <span class="k">return</span> <span class="n">z</span> <span class="o">*</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [10]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se calcula la función ReLU a partir del rango de valores</span></span>
<span class="code-line"><span class="n">c</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [11]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se gráfica la función</span></span>
<span class="code-line"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">c</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>Out[11]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="p">[</span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span> <span class="n">at</span> <span class="mh">0x7f90ba46c6d8</span><span class="o">&gt;</span><span class="p">]</span></span>
<span class="code-line"></code></pre></div>

<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-5.png"> </p>
<p>In [12]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Función tangente hiperbolico</span></span>
<span class="code-line"><span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">z</span><span class="p">):</span></span>
<span class="code-line">    <span class="k">return</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span></span>
<span class="code-line"></code></pre></div>

<p>In [13]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se calcula la tangente hiperbolica a partir del rango de valores</span></span>
<span class="code-line"><span class="n">d</span> <span class="o">=</span> <span class="n">tanh</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [14]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se gráfica</span></span>
<span class="code-line"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">d</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>Out[14]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code>[&lt;matplotlib.lines.Line2D at 0x7f90ba42e550&gt;]</span>
<span class="code-line"></code></pre></div>

<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-6.png"> </p>
<p>In [15]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Función sigmoide</span></span>
<span class="code-line"><span class="k">def</span> <span class="nf">sigmoide</span><span class="p">(</span><span class="n">z</span><span class="p">):</span></span>
<span class="code-line">    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span></span>
<span class="code-line"></code></pre></div>

<p>In [16]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se calcula la sigmoide a partir del rango de valores</span></span>
<span class="code-line"><span class="n">e</span> <span class="o">=</span> <span class="n">sigmoide</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [17]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se gráfica la función</span></span>
<span class="code-line"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">e</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>Out[17]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="p">[</span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span> <span class="n">at</span> <span class="mh">0x7f90ba3f0be0</span><span class="o">&gt;</span><span class="p">]</span></span>
<span class="code-line"></code></pre></div>

<p><img alt="" src="./images/funcionesdeactivacionparaunperceptron-7.png"> </p>
<p>La diferencia entre las funciones de activación es lo suavizada o no de cada curva. Osea, que tan abrupta es su pendiente, o la derivada de la función.</p>
<p>A continuación se crea una red neuronal usando scikit-learn  </p>
<p>In [18]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se importa de la red neuronal MLPClassifier</span></span>
<span class="code-line"><span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span></span>
<span class="code-line"></code></pre></div>

<p>In [19]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se definen los datos de entrada</span></span>
<span class="code-line"><span class="n">datos_entrada</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span></span>
<span class="code-line">    <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span></span>
<span class="code-line">    <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span></span>
<span class="code-line">    <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span></span>
<span class="code-line">    <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span></span>
<span class="code-line"><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [20]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se definen los datos de salida</span></span>
<span class="code-line"><span class="n">datos_salida</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,)</span></span>
<span class="code-line"></code></pre></div>

<p>In [21]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se crea la red neuronal con función de activación relu y 100 mil iteraciones</span></span>
<span class="code-line"><span class="n">model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span></span>
<span class="code-line"></code></pre></div>

<p>In [22]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se entrena a la red neuronal</span></span>
<span class="code-line"><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">,</span><span class="n">datos_salida</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>Out[22]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">power_t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [23]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se hace la predicción</span></span>
<span class="code-line"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;prediccion:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">))</span></span>
<span class="code-line"></span>
<span class="code-line"><span class="n">prediccion</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span><span class="p">]</span></span>
<span class="code-line"></code></pre></div>

<p>El resultado que devuelve la red neuronal debería ser [0,1,1,0] y devuelve [0,1,0,1] el cual es errado.
Se repite la construcción de la red neuronal, pero ahora usando la función de activación identity.</p>
<p>In [24]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;identity&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span></span>
<span class="code-line"></code></pre></div>

<p>In [25]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se entrena a la red neuronal</span></span>
<span class="code-line"><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">,</span><span class="n">datos_salida</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>Out[25]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;identity&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">power_t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [26]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se hace la predicción</span></span>
<span class="code-line"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;prediccion:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">))</span></span>
<span class="code-line"></span>
<span class="code-line"><span class="n">prediccion</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span></span>
<span class="code-line"></code></pre></div>

<p>El resultado que devuelve la red neuronal debería ser [0,1,1,0] y devuelve [0,0,0,0] el cual es errado.
Se repite la construcción de la red neuronal, pero ahora usando la función de activación sigmoide (logistic).  </p>
<p>In [27]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;logistic&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span></span>
<span class="code-line"></code></pre></div>

<p>In [28]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se entrena a la red neuronal</span></span>
<span class="code-line"><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">,</span><span class="n">datos_salida</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>Out[28]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;logistic&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">power_t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [29]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se hace la predicción</span></span>
<span class="code-line"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;prediccion:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">))</span></span>
<span class="code-line"></span>
<span class="code-line"><span class="n">prediccion</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span><span class="p">]</span></span>
<span class="code-line"></code></pre></div>

<p>El resultado que devuelve la red neuronal debería ser [0,1,1,0] y devuelve [1,1,1,1] el cual es errado.
Se repite la construcción de la red neuronal, pero ahora usando la función de activación tanh.  </p>
<p>In [33]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span></span>
<span class="code-line"></code></pre></div>

<p>In [34]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se entrena a la red neuronal</span></span>
<span class="code-line"><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">,</span><span class="n">datos_salida</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>Out[34]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">power_t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span></span>
<span class="code-line">       <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></span>
<span class="code-line"></code></pre></div>

<p>In [35]:</p>
<div class="highlight"><pre><span class="code-line"><span></span><code><span class="c1">#Se hace la predicción</span></span>
<span class="code-line"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;prediccion:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datos_entrada</span><span class="p">))</span></span>
<span class="code-line"></span>
<span class="code-line"><span class="n">prediccion</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span><span class="p">]</span></span>
<span class="code-line"></code></pre></div>

<p>El resultado que devuelve la red neuronal debería ser [0,1,1,0] y devuelve [0,1,1,0] el cual es el resultado esperado. Esto demuestra que es muy importante seleccionar la función de activación correcta a la hora de definir una red neuronal y entrenarla.</p>
<h2></h2>
<p>¡Haz tu donativo!
Si te gustó el artículo puedes realizar un donativo con Bitcoin (BTC)
usando la billetera digital de tu preferencia a la siguiente
dirección: 17MtNybhdkA9GV3UNS6BTwPcuhjXoPrSzV</p>
<p>O Escaneando el código QR desde la billetera:</p>
<p><img alt="17MtNybhdkA9GV3UNS6BTwPcuhjXoPrSzV" src="./images/17MtNybhdkA9GV3UNS6BTwPcuhjXoPrSzV.png"></p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://blog.seraph.to/tag/scikit-learn.html">Scikit-learn</a>
      <a href="https://blog.seraph.to/tag/python.html">Python</a>
      <a href="https://blog.seraph.to/tag/inteligencia-artificial.html">Inteligencia Artificial</a>
    </p>
  </div>

<section>
  <p id="post-share-links">
    Share on:
    <a href="mailto:?subject=Funciones%20de%20activaci%C3%B3n%20para%20un%20perceptron&amp;body=https%3A//blog.seraph.to/funciones-de-activacion-para-un-perceptron.html" title="Share via Email">Email</a>
    |
    <a href="https://sharetodiaspora.github.io/?title=Funciones%20de%20activaci%C3%B3n%20para%20un%20perceptron&url=https%3A//blog.seraph.to/funciones-de-activacion-para-un-perceptron.html" title="Share on Diaspora">Diaspora</a>
    |
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//blog.seraph.to/funciones-de-activacion-para-un-perceptron.html" title="Share on Facebook">Facebook</a>
    |
    <a href="https://news.ycombinator.com/submitlink?t=Funciones%20de%20activaci%C3%B3n%20para%20un%20perceptron&u=https%3A//blog.seraph.to/funciones-de-activacion-para-un-perceptron.html" title="Share on Hacker News">Hacker News</a>
    |
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//blog.seraph.to/funciones-de-activacion-para-un-perceptron.html&title=Funciones%20de%20activaci%C3%B3n%20para%20un%20perceptron&summary=En%20el%20art%C3%ADculo%20%28introducci%C3%B3n%20al%20perceptron%29%2C%20se%20muestra%20el%20perceptron%20con%20la%20funci%C3%B3n%20de%20activaci%C3%B3n%20que%20en%20la%20figura%20es%20una%20onda%20cuadrada%2C%20pero%20puede%20ser%20tambi%C3%A9n%20otro%20tipo%20de%20funci%C3%B3n.%0A%20%0AEn%20el%20art%C3%ADculo%20%20%28construir%20una%20red%20neuronal%20en%20pocos%20minutos%29%2C%20se%20muestra%20la%20funci%C3%B3n%20de%20activaci%C3%B3n%20llamada%20sigmoide.%0A%20%0AY%20%E2%80%A6&source=https%3A//blog.seraph.to/funciones-de-activacion-para-un-perceptron.html" title="Share on LinkedIn">LinkedIn</a>
    |
    <a href="" title="Share on Mastodon">Mastodon</a>
    |
    <a href="https://www.reddit.com/submit?url=https%3A//blog.seraph.to/funciones-de-activacion-para-un-perceptron.html&title=Funciones%20de%20activaci%C3%B3n%20para%20un%20perceptron" title="Share via Reddit">Reddit</a>
    |
    <a href="https://twitter.com/intent/tweet?text=Funciones%20de%20activaci%C3%B3n%20para%20un%20perceptron&url=https%3A//blog.seraph.to/funciones-de-activacion-para-un-perceptron.html&hashtags=scikit-learn,python,inteligencia-artificial" title="Share on Twitter">Twitter</a>
    |
    <a href="" title="Share on Bluesky">Bluesky</a>
  </p>
</section>


  <div class="neighbors">
    <a class="btn float-left" href="https://blog.seraph.to/visualizacion-de-objetos-graph-con-tensorboard.html" title="Visualización de objetos Graph con Tensorboard">
      <i class="fa fa-angle-left"></i> Previous Post
    </a>
    <a class="btn float-right" href="https://blog.seraph.to/obtener-cotizacion-de-bitcoin-de-coinmarketcap-con-python.html" title="Obtener cotización de bitcoin de coinmarketcap con Python">
      Next Post <i class="fa fa-angle-right"></i>
    </a>
  </div>

  <div class="related-posts">
    <h4>You might enjoy</h4>
    <ul class="related-posts">
      <li><a href="https://blog.seraph.to/algoritmo-de-clasificacion-con-scikit-learn.html">Algoritmo de Clasificación con scikit-learn</a></li>
      <li><a href="https://blog.seraph.to/una-red-neuronal-para-aprendizaje-supervisado-usando-scikit-learn.html">Una red Neuronal para aprendizaje supervisado usando Scikit-learn</a></li>
      <li><a href="https://blog.seraph.to/visualizacion-de-arbol-de-decision.html">Visualización de Árbol de decisión</a></li>
      <li><a href="https://blog.seraph.to/arbol-de-decision-hecho-en-python.html">Árbol de decisión hecho en Python</a></li>
      <li><a href="https://blog.seraph.to/construir-una-red-neuronal-en-pocos-minutos.html">Construir una red neuronal en pocos minutos</a></li>
    </ul>
  </div>


    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <ins class="adsbygoogle ads-responsive"
         data-ad-client="pub-0261001661746989"
         data-ad-slot="1234566"></ins>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
    </script>

<!-- Disqus -->
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'https://seraphto.disqus.com';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
    Please enable JavaScript to view comments.
</noscript>
<!-- End Disqus -->
</article>

<footer>
<p>&copy; 2022 </p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p></footer>  </main>

<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Página de Seraph ",
  "url" : "https://blog.seraph.to",
  "image": "//s.gravatar.com/avatar/7fab2070e149e57fe99da94d7ccbad6b?s=120",
  "description": " Software Libre, Ciencia de Datos y Python"
}
</script>
</body>
</html>